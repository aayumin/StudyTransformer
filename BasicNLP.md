# 딥러닝을 이용한 자연어처리와 RNN 구조

## 목차
1. 자연어처리(NLP)란 무엇인가?
2. 전통적인 자연어처리 방식들
3. 딥러닝 도입과 RNN 구조
4. RNN이 무엇인가?

---

## 자연어처리(NLP)란 무엇인가?

<img width="396" height="131" alt="image" src="https://github.com/user-attachments/assets/66dd78e8-df15-4f37-bf5a-6e4080fb4b4b" />

자연어처리(NLP, Natural Language Processing)는 **컴퓨터가 인간의 언어를 이해하고 처리하는 기술**을 말합니다. 우리의 일상적인 언어인 **자연어**를 컴퓨터가 분석하고, 의미를 추출하거나 결과를 도출하는 과정입니다.

### 비유:
우리가 사람에게 질문을 던지면, 사람은 질문을 듣고 그 의미를 파악하여 적절한 답변을 합니다. 마찬가지로 자연어처리 기술을 사용하면, 컴퓨터가 **텍스트**나 **음성**을 통해 전달된 언어를 **이해하고** **작업을 수행**할 수 있습니다.

### 예시:
- **텍스트 분류**: 뉴스 기사가 정치 관련인지, 스포츠 관련인지 구별하기
- **번역**: 영어 문장을 한국어로 번역하기
- **감정 분석**: 트위터 글을 분석하여 긍정적인지 부정적인지 판단하기

</br> </br>

---

## 전통적인 자연어처리 방식들

과거 자연어처리에서는 **규칙 기반 접근법** (Rule-based Approach)이 사용되었습니다. 이 방식은 **사람이 직접 규칙을 정**하여 자연어를 처리하는 방법입니다. 예를 들어, 텍스트에서 **명사**, **동사**, **형용사** 등을 찾아내는 규칙을 만들고, 이를 이용해 문장을 분석하는 방식입니다.

### 예시:
1. **토큰화 (Tokenization)**: 문장을 단어로 나누는 작업
2. **형태소 분석**: 단어를 의미 있는 최소 단위로 분해
3. **문법 규칙**: 문장 내에서 단어들이 어떻게 연결되는지 규칙 정의

### 단점:
- **복잡성**: 문법 규칙을 수동으로 정의해야 하므로 매우 복잡합니다.
- **유연성 부족**: 새로운 언어나 문장이 나오면 기존 규칙을 수정하거나 새로 만들어야 합니다.

</br> </br>

---

## 딥러닝 도입과 RNN 구조

딥러닝이 자연어처리에서 각광받기 시작한 이유는 **대규모 데이터**와 **컴퓨터의 하드웨어 성능** 덕분에 **자동으로 패턴을 학습**할 수 있게 되었기 때문입니다. 딥러닝은 **학습 데이터에서 특징을 자동으로 추출**하여, 사람이 일일이 규칙을 만들지 않아도 **더 유연하고 효율적으로** 자연어를 처리할 수 있습니다.

이때 자연어처리 분야에서 사용하는 딥러닝 모델은 `RNN (Recurrent Neural Network)` 계열이 많습니다.

<img width="1163" height="346" alt="image" src="https://github.com/user-attachments/assets/68be9429-5a6a-430e-841e-5b174d03b259" />

RNN은 **순차적인 데이터**를 처리하는 데 특화된 **인공 신경망**입니다. 자연어처리에서 텍스트는 단어들이 차례대로 나열되어 있는 **순차적인 정보**이기 때문에, RNN은 문맥을 이해하는 데 매우 유용합니다.

</br> </br>

---

## RNN이 무엇인가?

RNN(순환 신경망, Recurrent Neural Network)은 **입력 데이터가 시간에 따라 변하거나 순차적일 때** 효과적으로 작동하는 신경망입니다. **이전 상태의 정보를 기억**하고, 그것을 **현재 상태에 반영**하는 방식으로 동작합니다.

### 비유:
RNN을 사람이 이야기하는 것에 비유할 수 있습니다. 예를 들어, 사람이 긴 이야기를 할 때, 이전에 말한 내용이 그 다음에 말할 내용에 영향을 미칩니다. 만약 어떤 사람이 "어제 친구랑 영화를 봤어"라고 말하고, 그 후에 "영화 내용이 너무 재미있었어"라고 말한다면, 두 번째 문장은 첫 번째 문장의 영향을 받습니다. 마찬가지로, RNN은 이전의 입력이 다음의 출력에 영향을 주도록 학습합니다.

### 동작 방식:
1. **입력**: 매 시점마다 하나의 데이터(예: 단어, 문자 등)가 입력됩니다.
2. **순환**: 입력된 데이터는 **이전의 상태** 에 작용하여 **새로운 현재 상태** 가 만들어집니다.
3. **출력**: 최종적으로 변환된 상태를 바탕으로 출력이 생성됩니다.


</br> </br>

### 왜 자연어처리에 RNN이 필요한가?

자연어처리는 기본적으로 **순차적 정보**를 처리하는 작업이기 때문에, 각 단어가 이전 단어와 문맥을 통해 의미를 가지게 됩니다. 
예를 들어, `나는 인형을 선물 받았다. 그리고 그것을 친구에게 줬다.`라는 문장이 주어졌을 때, **그것**이라는 단어를 그 앞의 문장과 연결지으면 "그것"이 **인형**을 뜻한다고 이해할 수 있습니다. 
이를 위해서는 **과거 단어**들의 정보를 기억하고 있어야 하며, 이 때 중요한 역할을 하는 것이 바로 **RNN**입니다.

</br> </br>

### RNN의 한계와 발전

RNN은 기본적으로 잘 작동하지만, **긴 문장**이나 **긴 시퀀스**에서 발생하는 **장기 의존성 문제**가 있습니다. 즉, 문장이 길어질수록 이전 정보가 희미해져서 모델이 중요한 정보를 잃어버릴 수 있습니다. 이 문제를 해결하기 위해 LSTM (Long Short Term Memory)이나 GRU (Gated Recurrent Unit)와 같은 **고급 RNN 구조**가 도입되었습니다.

<img width="1774" height="499" alt="image" src="https://github.com/user-attachments/assets/12dda733-bf26-4c79-add8-9b0b6ac7135e" />


- **LSTM**: RNN의 한계를 극복하기 위해 설계되었으며, **기억을 선택적으로 저장하여 긴 문장에서도 정보를 오래 유지할 수 있도록** 하는 방식의 신경망입니다.
- **GRU**: LSTM보다 더 간단한 구조로 비슷한 성능을 보여주는 모델입니다.

---
